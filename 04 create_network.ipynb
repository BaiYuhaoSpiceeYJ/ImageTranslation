{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_set:\n",
    "    def __init__(self):\n",
    "        self.num_data = 31461\n",
    "        self.squared_img_path = \".\\\\flickr30k_squared\"\n",
    "        self.blured_img_path = \".\\\\flickr30k_blured\"\n",
    "        self.indicator = 0\n",
    "        self.index = [i for i in range(31461)]\n",
    "        self.index = np.random.permutation(self.index)\n",
    "        \n",
    "    def next_batch(self,batch_size):\n",
    "            \n",
    "        end_indicator = self.indicator + batch_size\n",
    "        if end_indicator >= self.num_data:\n",
    "            self.index = np.random.permutation(self.index)\n",
    "            self.indicator = 0\n",
    "            end_indicator = self.indicator + batch_size\n",
    "        assert end_indicator < self.num_data\n",
    "        \n",
    "        \n",
    "        batch_img_index = self.index[self.indicator: end_indicator]\n",
    "        batch_squared_img = []\n",
    "        batch_blured_img = []\n",
    "        \n",
    "        for img_index in batch_img_index:\n",
    "            squared_img_path = os.path.join(self.squared_img_path,\"%d.jpg\" % img_index)\n",
    "            blured_img_path = os.path.join(self.blured_img_path,\"%d.jpg\" % img_index)\n",
    "            \n",
    "            squared_img = np.array(cv2.imread(squared_img_path,1),dtype = np.float32)\n",
    "            blured_img = np.array(cv2.imread(blured_img_path,1),dtype = np.float32)\n",
    "            squared_img = (squared_img-127.5)/127.5\n",
    "            blured_img = (blured_img-127.5)/127.5\n",
    "            \n",
    "            batch_squared_img.append(squared_img)\n",
    "            batch_blured_img.append(blured_img)\n",
    "        \n",
    "        self.indicator = end_indicator\n",
    "        \n",
    "        if batch_size ==1:#用于测试\n",
    "            batch_squared_img = []\n",
    "            batch_blured_img = []\n",
    "            squared_img_path = os.path.join(self.squared_img_path,\"%d.jpg\" % 0)\n",
    "            blured_img_path = os.path.join(self.blured_img_path,\"%d.jpg\" % 0)\n",
    "            squared_img = np.array(cv2.imread(squared_img_path,1),dtype = np.float32)\n",
    "            blured_img = np.array(cv2.imread(blured_img_path,1),dtype = np.float32)\n",
    "            squared_img = (squared_img-127.5)/127.5\n",
    "            blured_img = (blured_img-127.5)/127.5\n",
    "            batch_squared_img.append(squared_img)\n",
    "            batch_blured_img.append(blured_img)\n",
    "        return batch_squared_img,batch_blured_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.placeholder(tf.float32,[None,256,256,3])\n",
    "y_image = tf.placeholder(tf.float32,[None,256,256,3])    \n",
    "\n",
    "conv1 = tf.layers.conv2d(x_image,64,(3,3),padding='same',activation=None,name='conv1')#256*256*3 -> 256*256*64\n",
    "bn1 = tf.nn.relu(tf.layers.batch_normalization(conv1))\n",
    "pooling1 = tf.layers.max_pooling2d(bn1,(2,2),(2,2),name = 'pool1') #256*256*64 -> 128*128*64\n",
    "\n",
    "conv2 = tf.layers.conv2d(pooling1,128,(3,3),padding='same',activation=None,name='conv2')#128*128*64 -> 128*128*128\n",
    "bn2 = tf.nn.relu(tf.layers.batch_normalization(conv2))\n",
    "pooling2 = tf.layers.max_pooling2d(bn2,(2,2),(2,2),name = 'pool2')#128*128*128 ->64*64*128\n",
    "\n",
    "conv3 = tf.layers.conv2d(pooling2,256,(3,3),padding='same',activation=None,name='econv3')#64*64*128 -> 64*64*256\n",
    "bn3 = tf.nn.relu(tf.layers.batch_normalization(conv3))\n",
    "pooling3 = tf.layers.max_pooling2d(bn3,(2,2),(2,2),name = 'pool3')#64*64*256 -> 32*32*256\n",
    "\n",
    "conv4 = tf.layers.conv2d(pooling3,512,(3,3),padding='same',activation=None,name='conv4')#32*32*256 -> 32*32*512\n",
    "bn4 = tf.nn.relu(tf.layers.batch_normalization(conv4))\n",
    "pooling4 = tf.layers.max_pooling2d(bn4,(2,2),(2,2),name = 'pool4')#32*32*512 -> 16*16*512\n",
    "\n",
    "conv5 = tf.layers.conv2d(pooling4,512,(3,3),padding='same',activation=None,name='conv5')#16*16*512 -> 16*16*512\n",
    "bn5 = tf.nn.relu(tf.layers.batch_normalization(conv5))\n",
    "pooling5 = tf.layers.max_pooling2d(bn5,(2,2),(2,2),name = 'pool5')#16*16*512 -> 8*8*512\n",
    "\n",
    "conv6 = tf.layers.conv2d(pooling5,512,(3,3),padding='same',activation=None,name='conv6')#8*8*512 -> 8*8*512\n",
    "bn6 = tf.nn.relu(tf.layers.batch_normalization(conv6))\n",
    "pooling6 = tf.layers.max_pooling2d(bn6,(2,2),(2,2),name = 'pool6')#8*8*512 -> 4*4*512\n",
    "\n",
    "conv7 = tf.layers.conv2d(pooling6,512,(3,3),padding='same',activation=None,name='conv7')#4*4*512 -> 4*4*512\n",
    "bn7 = tf.nn.relu(tf.layers.batch_normalization(conv7))\n",
    "pooling7 = tf.layers.max_pooling2d(bn7,(2,2),(2,2),name = 'pool7')#4*4*512 -> 2*2*512\n",
    "\n",
    "conv8 = tf.layers.conv2d(pooling7,512,(3,3),padding='same',activation=None,name='conv8')#2*2*512 -> 2*2*512\n",
    "bn8 = tf.nn.relu(tf.layers.batch_normalization(conv8))\n",
    "pooling8 = tf.layers.max_pooling2d(bn8,(2,2),(2,2),name = 'pool8')#2*2*512 -> 1*1*512\n",
    "\n",
    "conv1_transpose = tf.layers.conv2d_transpose(pooling8, 512,[3,3],strides=(2,2),padding='SAME')#1*1*512 -> 2*2*512\n",
    "bn1_transpose = tf.nn.relu(tf.layers.batch_normalization(conv1_transpose))\n",
    "bn1_transpose_res = bn1_transpose + 0.5*pooling7\n",
    "\n",
    "conv2_transpose = tf.layers.conv2d_transpose(bn1_transpose_res, 512,[3,3],strides=(2,2),padding='SAME')#2*2*512 -> 4*4*512\n",
    "bn2_transpose = tf.nn.relu(tf.layers.batch_normalization(conv2_transpose))\n",
    "bn2_transpose_res = bn2_transpose + 0.25*pooling6\n",
    "\n",
    "conv3_transpose = tf.layers.conv2d_transpose(bn2_transpose_res, 512,[3,3],strides=(2,2),padding='SAME')#4*4*512 -> 8*8*512\n",
    "bn3_transpose = tf.nn.relu(tf.layers.batch_normalization(conv3_transpose))\n",
    "bn3_transpose_res = bn3_transpose + 0.12*pooling5\n",
    "\n",
    "conv4_transpose = tf.layers.conv2d_transpose(bn3_transpose_res, 512,[3,3],strides=(2,2),padding='SAME')#8*8*512 -> 16*16*512\n",
    "bn4_transpose = tf.nn.relu(tf.layers.batch_normalization(conv4_transpose))\n",
    "bn4_transpose_res = bn4_transpose + 0.06*pooling4\n",
    "\n",
    "conv5_transpose = tf.layers.conv2d_transpose(bn4_transpose_res, 256,[3,3],strides=(2,2),padding='SAME')#16*16*512->32*32*256\n",
    "bn5_transpose = tf.nn.relu(tf.layers.batch_normalization(conv5_transpose))\n",
    "bn5_transpose_res = bn5_transpose + 0.03*pooling3\n",
    "\n",
    "conv6_transpose = tf.layers.conv2d_transpose(bn5_transpose_res, 128,[3,3],strides=(2,2),padding='SAME')#32*32*256->64*64*128\n",
    "bn6_transpose = tf.nn.relu(tf.layers.batch_normalization(conv6_transpose))\n",
    "bn6_transpose_res = bn6_transpose + 0.015*pooling2\n",
    "\n",
    "conv7_transpose = tf.layers.conv2d_transpose(bn6_transpose_res, 64,[3,3],strides=(2,2),padding='SAME')#64*64*128->128*128*64\n",
    "bn7_transpose = tf.nn.relu(tf.layers.batch_normalization(conv7_transpose))\n",
    "bn7_transpose_res = bn7_transpose #+ 0.0000*pooling1\n",
    "\n",
    "y_image_predict = tf.nn.relu(tf.layers.conv2d_transpose(bn7_transpose_res, 3,[3,3],strides=(2,2),padding='SAME'))#128*128*64->256*256*3\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_image-y_image_predict))\n",
    "tf.summary.scalar('loss',loss)\n",
    "global_step = tf.Variable(0,trainable=False)#训练的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "train_steps = 100000\n",
    "img_set = Image_set()\n",
    "\n",
    "\n",
    "model_dir = '.\\\\run_model'\n",
    "log_dir ='.\\\\run_log'\n",
    "test_dir = '.\\\\test_img'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(log_dir,sess.graph)\n",
    "    sess.run(init_op)\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, os.path.join(model_dir, ckpt_name))\n",
    "        \n",
    "    test  = True    \n",
    "    #for step in range(train_steps):\n",
    "    for step in range(1):\n",
    "        if not test:\n",
    "            start_time = time.time()\n",
    "            batch_squared_img,batch_blured_img = img_set.next_batch(batch_size)\n",
    "            global_step_val,losses,losses_merged,_= sess.run([global_step,loss,merged,train_op],\n",
    "                                                          feed_dict={x_image:batch_blured_img , y_image:batch_squared_img})\n",
    "        \n",
    "            use_time = time.time()-start_time\n",
    "            print(\"global_step=\",global_step_val,\" losses=\",losses,\" time=%02fs\"%use_time)\n",
    "        \n",
    "            if global_step_val%50 ==0:\n",
    "                writer.add_summary(losses_merged,global_step_val)\n",
    "                saver.save(sess,os.path.join(model_dir,'ckp-%06d' %global_step_val))\n",
    "                print('model saved to ckp-%06d' %global_step_val)\n",
    "                test = True\n",
    "            \n",
    "        else:    #每50步测试一下图片生成情况\n",
    "            batch_squared_img,batch_blured_img = img_set.next_batch(1)\n",
    "            global_step_val,generated_imgs = sess.run([global_step,y_image_predict],\n",
    "                                                        feed_dict={x_image:batch_blured_img , y_image:batch_squared_img})\n",
    "            #不训练执行train_op的时候，global_step_val不会+1\n",
    "            img = generated_imgs[-1]\n",
    "            img = (img+1)*127.5\n",
    "            img = np.array(img,dtype = np.uint8)\n",
    "            out_put_path = os.path.join(test_dir,\"%06d.jpg\" %global_step_val)\n",
    "            cv2.imwrite(out_put_path,img)\n",
    "            #cv2.imshow('a',img)\n",
    "            #cv2.waitKey()\n",
    "            test = False\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
