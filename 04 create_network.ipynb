{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_set:\n",
    "    def __init__(self):\n",
    "        self.num_data = 31461\n",
    "        self.squared_img_path = \".\\\\flickr30k_squared\"\n",
    "        self.blured_img_path = \".\\\\flickr30k_blured\"\n",
    "        self.indicator = 0\n",
    "        self.index = [i for i in range(31461)]\n",
    "        self.index = np.random.permutation(self.index)\n",
    "        \n",
    "    def next_batch(self,batch_size):\n",
    "            \n",
    "        end_indicator = self.indicator + batch_size\n",
    "        if end_indicator >= self.num_data:\n",
    "            self.index = np.random.permutation(self.index)\n",
    "            self.indicator = 0\n",
    "            end_indicator = self.indicator + batch_size\n",
    "        assert end_indicator < self.num_data\n",
    "        \n",
    "        \n",
    "        batch_img_index = self.index[self.indicator: end_indicator]\n",
    "        batch_squared_img = []\n",
    "        batch_blured_img = []\n",
    "        \n",
    "        for img_index in batch_img_index:\n",
    "            squared_img_path = os.path.join(self.squared_img_path,\"%d.jpg\" % img_index)\n",
    "            blured_img_path = os.path.join(self.blured_img_path,\"%d.jpg\" % img_index)\n",
    "            \n",
    "            squared_img = np.array(cv2.imread(squared_img_path,1),dtype = np.float32)\n",
    "            blured_img = np.array(cv2.imread(blured_img_path,1),dtype = np.float32)\n",
    "            squared_img = (squared_img-127.5)/127.5\n",
    "            blured_img = (blured_img-127.5)/127.5\n",
    "            \n",
    "            batch_squared_img.append(squared_img)\n",
    "            batch_blured_img.append(blured_img)\n",
    "        \n",
    "        self.indicator = end_indicator\n",
    "        \n",
    "        if batch_size ==1:#用于测试\n",
    "            batch_squared_img = []\n",
    "            batch_blured_img = []\n",
    "            squared_img_path = os.path.join(self.squared_img_path,\"%d.jpg\" % 0)\n",
    "            blured_img_path = os.path.join(self.blured_img_path,\"%d.jpg\" % 0)\n",
    "            squared_img = np.array(cv2.imread(squared_img_path,1),dtype = np.float32)\n",
    "            blured_img = np.array(cv2.imread(blured_img_path,1),dtype = np.float32)\n",
    "            squared_img = (squared_img-127.5)/127.5\n",
    "            blured_img = (blured_img-127.5)/127.5\n",
    "            batch_squared_img.append(squared_img)\n",
    "            batch_blured_img.append(blured_img)\n",
    "        return batch_squared_img,batch_blured_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.placeholder(tf.float32,[None,256,256,3])\n",
    "y_image = tf.placeholder(tf.float32,[None,256,256,3])    \n",
    "\n",
    "conv1_1 = tf.layers.conv2d(x_image,64,(3,3),padding='same',activation=None,name='conv1_1')#256*256*3 -> 256*256*64\n",
    "conv1_2 = tf.layers.conv2d(conv1_1,64,(3,3),padding='same',activation=None,name='conv1_2')\n",
    "conv1_3 = tf.layers.conv2d(conv1_2,64,(3,3),padding='same',activation=None,name='conv1_3')\n",
    "bn1 = tf.nn.relu(tf.layers.batch_normalization(conv1_3))\n",
    "pooling1 = tf.layers.max_pooling2d(bn1,(2,2),(2,2),name = 'pool1') #256*256*64 -> 128*128*64\n",
    "\n",
    "conv2_1 = tf.layers.conv2d(pooling1,128,(3,3),padding='same',activation=None,name='conv2_1')#128*128*64 -> 128*128*128\n",
    "conv2_2 = tf.layers.conv2d(conv2_1,128,(3,3),padding='same',activation=None,name='conv2_2')\n",
    "conv2_3 = tf.layers.conv2d(conv2_2,128,(3,3),padding='same',activation=None,name='conv2_3')\n",
    "bn2 = tf.nn.relu(tf.layers.batch_normalization(conv2_3))\n",
    "pooling2 = tf.layers.max_pooling2d(bn2,(2,2),(2,2),name = 'pool2')#128*128*128 ->64*64*128\n",
    "\n",
    "conv3_1 = tf.layers.conv2d(pooling2,256,(3,3),padding='same',activation=None,name='conv3_1')#64*64*128 -> 64*64*256\n",
    "conv3_2 = tf.layers.conv2d(conv3_1,256,(3,3),padding='same',activation=None,name='conv3_2')\n",
    "conv3_3 = tf.layers.conv2d(conv3_2,256,(3,3),padding='same',activation=None,name='conv3_3')\n",
    "bn3 = tf.nn.relu(tf.layers.batch_normalization(conv3_3))\n",
    "pooling3 = tf.layers.max_pooling2d(bn3,(2,2),(2,2),name = 'pool3')#64*64*256 -> 32*32*256\n",
    "\n",
    "conv4_1 = tf.layers.conv2d(pooling3,512,(3,3),padding='same',activation=None,name='conv4_1')#32*32*256 -> 32*32*512\n",
    "conv4_2 = tf.layers.conv2d(conv4_1,512,(3,3),padding='same',activation=None,name='conv4_2')\n",
    "bn4 = tf.nn.relu(tf.layers.batch_normalization(conv4_2))\n",
    "pooling4 = tf.layers.max_pooling2d(bn4,(2,2),(2,2),name = 'pool4')#32*32*512 -> 16*16*512\n",
    "\n",
    "conv5_1 = tf.layers.conv2d(pooling4,512,(3,3),padding='same',activation=None,name='conv5_1')#16*16*512 -> 16*16*512\n",
    "conv5_2 = tf.layers.conv2d(conv5_1,512,(3,3),padding='same',activation=None,name='conv5_2')\n",
    "bn5 = tf.nn.relu(tf.layers.batch_normalization(conv5_2))\n",
    "pooling5 = tf.layers.max_pooling2d(bn5,(2,2),(2,2),name = 'pool5')#16*16*512 -> 8*8*512\n",
    "\n",
    "conv6_1 = tf.layers.conv2d(pooling5,512,(3,3),padding='same',activation=None,name='conv6_1')#8*8*512 -> 8*8*512\n",
    "conv6_2 = tf.layers.conv2d(conv6_1,512,(3,3),padding='same',activation=None,name='conv6_2')\n",
    "bn6 = tf.nn.relu(tf.layers.batch_normalization(conv6_2))\n",
    "pooling6 = tf.layers.max_pooling2d(bn6,(2,2),(2,2),name = 'pool6')#8*8*512 -> 4*4*512\n",
    "\n",
    "conv7_1 = tf.layers.conv2d(pooling6,512,(3,3),padding='same',activation=None,name='conv7_1')#4*4*512 -> 4*4*512\n",
    "conv7_2 = tf.layers.conv2d(conv7_1,512,(3,3),padding='same',activation=None,name='conv7_2')\n",
    "bn7 = tf.nn.relu(tf.layers.batch_normalization(conv7_2))\n",
    "pooling7 = tf.layers.max_pooling2d(bn7,(2,2),(2,2),name = 'pool7')#4*4*512 -> 2*2*512\n",
    "\n",
    "conv8_1 = tf.layers.conv2d(pooling7,512,(3,3),padding='same',activation=None,name='conv8_1')#2*2*512 -> 2*2*512\n",
    "conv8_2 = tf.layers.conv2d(conv8_1,512,(3,3),padding='same',activation=None,name='conv8_2')\n",
    "bn8 = tf.nn.relu(tf.layers.batch_normalization(conv8_2))\n",
    "pooling8 = tf.layers.max_pooling2d(bn8,(2,2),(2,2),name = 'pool8')#2*2*512 -> 1*1*512\n",
    "\n",
    "conv1_transpose = tf.layers.conv2d_transpose(pooling8, 512,[3,3],strides=(2,2),padding='SAME')#1*1*512 -> 2*2*512\n",
    "conv1_tr_1 = tf.layers.conv2d(conv1_transpose,512,(3,3),padding='same',activation=None,name='conv1_tr_1')\n",
    "bn1_transpose = tf.nn.relu(tf.layers.batch_normalization(conv1_tr_1))\n",
    "bn1_transpose_res = bn1_transpose + 0.5*pooling7\n",
    "\n",
    "conv2_transpose = tf.layers.conv2d_transpose(bn1_transpose_res, 512,[3,3],strides=(2,2),padding='SAME')#2*2*512 -> 4*4*512\n",
    "conv2_tr_1 = tf.layers.conv2d(conv2_transpose,512,(3,3),padding='same',activation=None,name='conv2_tr_1')\n",
    "bn2_transpose = tf.nn.relu(tf.layers.batch_normalization(conv2_tr_1))\n",
    "bn2_transpose_res = bn2_transpose + 0.25*pooling6\n",
    "\n",
    "conv3_transpose = tf.layers.conv2d_transpose(bn2_transpose_res, 512,[3,3],strides=(2,2),padding='SAME')#4*4*512 -> 8*8*512\n",
    "conv3_tr_1 = tf.layers.conv2d(conv3_transpose,512,(3,3),padding='same',activation=None,name='conv3_tr_1')\n",
    "bn3_transpose = tf.nn.relu(tf.layers.batch_normalization(conv3_tr_1))\n",
    "bn3_transpose_res = bn3_transpose + 0.12*pooling5\n",
    "\n",
    "conv4_transpose = tf.layers.conv2d_transpose(bn3_transpose_res, 512,[3,3],strides=(2,2),padding='SAME')#8*8*512 -> 16*16*512\n",
    "conv4_tr_1 = tf.layers.conv2d(conv4_transpose,512,(3,3),padding='same',activation=None,name='conv4_tr_1')\n",
    "bn4_transpose = tf.nn.relu(tf.layers.batch_normalization(conv4_tr_1))\n",
    "bn4_transpose_res = bn4_transpose + 0.06*pooling4\n",
    "\n",
    "conv5_transpose = tf.layers.conv2d_transpose(bn4_transpose_res, 256,[3,3],strides=(2,2),padding='SAME')#16*16*512->32*32*256\n",
    "conv5_tr_1 = tf.layers.conv2d(conv5_transpose,256,(3,3),padding='same',activation=None,name='conv5_tr_1')\n",
    "conv5_tr_2 = tf.layers.conv2d(conv5_tr_1,256,(3,3),padding='same',activation=None,name='conv5_tr_2')\n",
    "bn5_transpose = tf.nn.relu(tf.layers.batch_normalization(conv5_tr_2))\n",
    "bn5_transpose_res = bn5_transpose + 0.03*pooling3\n",
    "\n",
    "conv6_transpose = tf.layers.conv2d_transpose(bn5_transpose_res, 128,[3,3],strides=(2,2),padding='SAME')#32*32*256->64*64*128\n",
    "conv6_tr_1 = tf.layers.conv2d(conv6_transpose,128,(3,3),padding='same',activation=None,name='conv6_tr_1')\n",
    "conv6_tr_2 = tf.layers.conv2d(conv6_tr_1,128,(3,3),padding='same',activation=None,name='conv6_tr_2')\n",
    "bn6_transpose = tf.nn.relu(tf.layers.batch_normalization(conv6_tr_2))\n",
    "bn6_transpose_res = bn6_transpose + 0.015*pooling2\n",
    "\n",
    "conv7_transpose = tf.layers.conv2d_transpose(bn6_transpose_res, 64,[3,3],strides=(2,2),padding='SAME')#64*64*128->128*128*64\n",
    "conv7_tr_1 = tf.layers.conv2d(conv7_transpose,64,(3,3),padding='same',activation=None,name='conv7_tr_1')\n",
    "conv7_tr_2 = tf.layers.conv2d(conv7_tr_1,64,(3,3),padding='same',activation=None,name='conv7_tr_2')\n",
    "bn7_transpose = tf.nn.relu(tf.layers.batch_normalization(conv7_tr_1))\n",
    "bn7_transpose_res = bn7_transpose #+ 0.0000*pooling1\n",
    "\n",
    "y_image_predict = tf.nn.relu(tf.layers.conv2d_transpose(bn7_transpose_res, 3,[3,3],strides=(2,2),padding='SAME'))#128*128*64->256*256*3\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_image-y_image_predict))\n",
    "tf.summary.scalar('loss',loss)\n",
    "global_step = tf.Variable(0,trainable=False)#训练的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\run_model\\ckp-000080\n",
      "global_step= 81  losses= 0.3479114  time=111.867347s\n",
      "global_step= 82  losses= 223.26933  time=101.384331s\n",
      "global_step= 83  losses= 0.37984633  time=98.641225s\n",
      "global_step= 84  losses= 0.75691444  time=97.887517s\n",
      "global_step= 85  losses= 0.3532084  time=98.976274s\n",
      "global_step= 86  losses= 0.41487536  time=99.548410s\n",
      "global_step= 87  losses= 0.48955622  time=98.842290s\n",
      "global_step= 88  losses= 0.34246767  time=101.156269s\n",
      "global_step= 89  losses= 0.29893652  time=100.512218s\n",
      "global_step= 90  losses= 0.36251378  time=99.130208s\n",
      "global_step= 91  losses= 0.33746898  time=100.886712s\n",
      "global_step= 92  losses= 0.33681068  time=99.163257s\n",
      "global_step= 93  losses= 0.3242388  time=98.563246s\n",
      "global_step= 94  losses= 0.31400704  time=98.882285s\n",
      "global_step= 95  losses= 0.37026867  time=98.260245s\n",
      "global_step= 96  losses= 0.32392922  time=98.515222s\n",
      "global_step= 97  losses= 0.31775248  time=98.191720s\n",
      "global_step= 98  losses= 0.3684592  time=98.061324s\n",
      "global_step= 99  losses= 0.36031303  time=98.700321s\n",
      "global_step= 100  losses= 0.3138367  time=99.111340s\n",
      "model saved to ckp-000100\n",
      "global_step= 101  losses= 0.32649463  time=103.605280s\n",
      "global_step= 102  losses= 0.39868942  time=99.277294s\n",
      "global_step= 103  losses= 0.33161053  time=99.147243s\n",
      "global_step= 104  losses= 0.34810433  time=97.859301s\n",
      "global_step= 105  losses= 0.32417873  time=98.774247s\n",
      "global_step= 106  losses= 0.35736957  time=98.353275s\n",
      "global_step= 107  losses= 0.37715158  time=97.871289s\n",
      "global_step= 108  losses= 0.345584  time=98.062262s\n",
      "global_step= 109  losses= 0.31408286  time=98.135274s\n",
      "global_step= 110  losses= 0.36546388  time=97.945291s\n",
      "global_step= 111  losses= 0.3379545  time=98.044325s\n",
      "global_step= 112  losses= 0.33952436  time=97.840339s\n",
      "global_step= 113  losses= 0.353693  time=99.473279s\n",
      "global_step= 114  losses= 0.39190897  time=97.791249s\n",
      "global_step= 115  losses= 0.3579528  time=97.991323s\n",
      "global_step= 116  losses= 0.33735207  time=97.793324s\n",
      "global_step= 117  losses= 0.41188884  time=97.939281s\n",
      "global_step= 118  losses= 0.35508165  time=98.457275s\n",
      "global_step= 119  losses= 0.36297107  time=98.408262s\n",
      "global_step= 120  losses= 0.34026918  time=97.967234s\n",
      "model saved to ckp-000120\n",
      "global_step= 121  losses= 0.32764423  time=103.730239s\n",
      "global_step= 122  losses= 0.39066458  time=99.939245s\n",
      "global_step= 123  losses= 0.39233127  time=99.199226s\n",
      "global_step= 124  losses= 0.36377084  time=97.754205s\n",
      "global_step= 125  losses= 0.35381827  time=98.106261s\n",
      "global_step= 126  losses= 0.33773002  time=98.353294s\n",
      "global_step= 127  losses= 0.3660519  time=98.848294s\n",
      "global_step= 128  losses= 0.31225047  time=98.191263s\n",
      "global_step= 129  losses= 0.3551612  time=98.267249s\n",
      "global_step= 130  losses= 0.3304218  time=98.018278s\n",
      "global_step= 131  losses= 0.33610204  time=97.867275s\n",
      "global_step= 132  losses= 0.34983042  time=98.594268s\n",
      "global_step= 133  losses= 0.366011  time=99.125251s\n",
      "global_step= 134  losses= 0.37629628  time=98.881278s\n",
      "global_step= 135  losses= 0.33109772  time=98.583268s\n",
      "global_step= 136  losses= 0.35764393  time=97.849205s\n",
      "global_step= 137  losses= 0.331302  time=98.655260s\n",
      "global_step= 138  losses= 0.32398042  time=98.419261s\n",
      "global_step= 139  losses= 0.35158488  time=98.104301s\n",
      "global_step= 140  losses= 0.36859074  time=98.237275s\n",
      "model saved to ckp-000140\n",
      "global_step= 141  losses= 0.36470267  time=102.280279s\n",
      "global_step= 142  losses= 0.37535396  time=101.023317s\n",
      "global_step= 143  losses= 0.382082  time=99.013269s\n",
      "global_step= 144  losses= 0.3588297  time=99.442258s\n",
      "global_step= 145  losses= 0.3528076  time=98.699256s\n",
      "global_step= 146  losses= 0.33116975  time=98.811312s\n",
      "global_step= 147  losses= 0.33421603  time=98.680220s\n",
      "global_step= 148  losses= 0.35241517  time=98.200274s\n",
      "global_step= 149  losses= 0.37639102  time=97.975292s\n",
      "global_step= 150  losses= 0.35298124  time=98.415287s\n",
      "global_step= 151  losses= 0.32745624  time=98.584238s\n",
      "global_step= 152  losses= 0.36762953  time=99.290236s\n",
      "global_step= 153  losses= 0.3388596  time=98.314214s\n",
      "global_step= 154  losses= 0.32843468  time=99.054215s\n",
      "global_step= 155  losses= 0.31062666  time=98.562238s\n",
      "global_step= 156  losses= 0.32397607  time=100.170278s\n",
      "global_step= 157  losses= 0.3663244  time=100.640222s\n",
      "global_step= 158  losses= 0.3347598  time=98.304258s\n",
      "global_step= 159  losses= 0.36423206  time=99.053337s\n",
      "global_step= 160  losses= 0.35461065  time=98.643324s\n",
      "model saved to ckp-000160\n",
      "global_step= 161  losses= 0.38246855  time=103.921312s\n",
      "global_step= 162  losses= 0.3748881  time=101.763324s\n",
      "global_step= 163  losses= 0.34481254  time=100.182296s\n",
      "global_step= 164  losses= 0.36526182  time=100.431285s\n",
      "global_step= 165  losses= 0.32287365  time=99.533271s\n",
      "global_step= 166  losses= 0.32917494  time=99.139354s\n",
      "global_step= 167  losses= 0.29877272  time=98.633296s\n",
      "global_step= 168  losses= 0.3641772  time=99.003269s\n",
      "global_step= 169  losses= 0.29827103  time=99.103265s\n",
      "global_step= 170  losses= 0.35342574  time=99.007236s\n",
      "global_step= 171  losses= 0.316824  time=98.859242s\n",
      "global_step= 172  losses= 0.31901333  time=98.920249s\n",
      "global_step= 173  losses= 0.30806664  time=100.309226s\n",
      "global_step= 174  losses= 0.3177648  time=99.829272s\n",
      "global_step= 175  losses= 0.34099913  time=98.924293s\n",
      "global_step= 176  losses= 0.33828297  time=98.709301s\n",
      "global_step= 177  losses= 0.34211794  time=98.914292s\n",
      "global_step= 178  losses= 0.3148824  time=99.187284s\n",
      "global_step= 179  losses= 0.34569296  time=99.111283s\n",
      "global_step= 180  losses= 0.31474456  time=98.948248s\n",
      "model saved to ckp-000180\n",
      "global_step= 181  losses= 0.35427132  time=103.825235s\n",
      "global_step= 182  losses= 0.32460007  time=101.042249s\n",
      "global_step= 183  losses= 0.37452435  time=100.196224s\n",
      "global_step= 184  losses= 0.35616505  time=99.878297s\n",
      "global_step= 185  losses= 0.35439435  time=99.112258s\n",
      "global_step= 186  losses= 0.36617163  time=98.755208s\n",
      "global_step= 187  losses= 0.36168298  time=98.982225s\n",
      "global_step= 188  losses= 0.35521302  time=98.994290s\n",
      "global_step= 189  losses= 0.35817266  time=98.547266s\n",
      "global_step= 190  losses= 0.32435405  time=99.128320s\n",
      "global_step= 191  losses= 0.33277547  time=98.565284s\n",
      "global_step= 192  losses= 0.29312018  time=99.000225s\n",
      "global_step= 193  losses= 0.3624847  time=99.795262s\n",
      "global_step= 194  losses= 0.30659816  time=100.262288s\n",
      "global_step= 195  losses= 0.29919305  time=98.299274s\n",
      "global_step= 196  losses= 0.34849298  time=98.349273s\n",
      "global_step= 197  losses= 0.34362468  time=98.736293s\n",
      "global_step= 198  losses= 0.36954007  time=98.930318s\n",
      "global_step= 199  losses= 0.35508683  time=99.115291s\n",
      "global_step= 200  losses= 0.34777403  time=98.423301s\n",
      "model saved to ckp-000200\n",
      "global_step= 201  losses= 0.32045516  time=104.313234s\n",
      "global_step= 202  losses= 0.3472735  time=101.480275s\n",
      "global_step= 203  losses= 0.35439515  time=99.582304s\n",
      "global_step= 204  losses= 0.37415126  time=99.278260s\n",
      "global_step= 205  losses= 0.36803684  time=97.370236s\n",
      "global_step= 206  losses= 0.3716476  time=98.534258s\n",
      "global_step= 207  losses= 0.34119844  time=97.958222s\n",
      "global_step= 208  losses= 0.36225113  time=99.034238s\n",
      "global_step= 209  losses= 0.34837136  time=98.964242s\n",
      "global_step= 210  losses= 0.3073096  time=99.181252s\n",
      "global_step= 211  losses= 0.34450555  time=98.734256s\n",
      "global_step= 212  losses= 0.38159823  time=100.318283s\n",
      "global_step= 213  losses= 0.35702714  time=98.891304s\n",
      "global_step= 214  losses= 0.39093614  time=98.685305s\n",
      "global_step= 215  losses= 0.329589  time=98.459274s\n",
      "global_step= 216  losses= 0.32792085  time=98.364301s\n",
      "global_step= 217  losses= 0.3419393  time=99.523308s\n",
      "global_step= 218  losses= 0.31893682  time=98.779253s\n",
      "global_step= 219  losses= 0.34594432  time=99.120234s\n",
      "global_step= 220  losses= 0.32546124  time=100.000214s\n",
      "model saved to ckp-000220\n",
      "global_step= 221  losses= 0.35067466  time=105.495226s\n",
      "global_step= 222  losses= 0.32401994  time=100.066209s\n",
      "global_step= 223  losses= 0.35950646  time=99.137278s\n",
      "global_step= 224  losses= 0.33856294  time=99.753310s\n",
      "global_step= 225  losses= 0.3453741  time=99.414257s\n",
      "global_step= 226  losses= 0.36862564  time=98.807275s\n",
      "global_step= 227  losses= 0.3451469  time=99.076302s\n",
      "global_step= 228  losses= 0.34447798  time=99.276272s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step= 229  losses= 0.34740353  time=101.336297s\n",
      "global_step= 230  losses= 0.34332335  time=100.607281s\n",
      "global_step= 231  losses= 0.34420648  time=99.642288s\n",
      "global_step= 232  losses= 0.3194202  time=99.046299s\n",
      "global_step= 233  losses= 0.3248087  time=99.099277s\n",
      "global_step= 234  losses= 0.34727302  time=99.099275s\n",
      "global_step= 235  losses= 0.33357897  time=100.095259s\n",
      "global_step= 236  losses= 0.3604271  time=99.717245s\n",
      "global_step= 237  losses= 0.33442697  time=100.583212s\n",
      "global_step= 238  losses= 0.32315525  time=100.581251s\n",
      "global_step= 239  losses= 0.3731998  time=99.784267s\n",
      "global_step= 240  losses= 0.32954165  time=99.196308s\n",
      "model saved to ckp-000240\n",
      "global_step= 241  losses= 0.32434973  time=102.891284s\n",
      "global_step= 242  losses= 0.36348686  time=101.139308s\n",
      "global_step= 243  losses= 0.3132596  time=99.864247s\n",
      "global_step= 244  losses= 0.33833444  time=98.826214s\n",
      "global_step= 245  losses= 0.35432807  time=99.240271s\n",
      "global_step= 246  losses= 0.32482964  time=100.875293s\n",
      "global_step= 247  losses= 0.33236763  time=99.165286s\n",
      "global_step= 248  losses= 0.34023213  time=98.405245s\n",
      "global_step= 249  losses= 0.37022987  time=99.105254s\n",
      "global_step= 250  losses= 0.344467  time=99.570193s\n",
      "global_step= 251  losses= 0.33038512  time=99.683219s\n",
      "global_step= 252  losses= 0.35285679  time=98.579262s\n",
      "global_step= 253  losses= 0.38556758  time=99.391227s\n",
      "global_step= 254  losses= 0.33929947  time=99.772258s\n",
      "global_step= 255  losses= 0.33512154  time=100.216246s\n",
      "global_step= 256  losses= 0.29059425  time=98.725231s\n",
      "global_step= 257  losses= 0.3535842  time=99.006275s\n",
      "global_step= 258  losses= 0.3819418  time=98.975280s\n",
      "global_step= 259  losses= 0.35878348  time=99.098286s\n",
      "global_step= 260  losses= 0.32794806  time=99.337401s\n",
      "model saved to ckp-000260\n",
      "global_step= 261  losses= 0.3420607  time=105.887292s\n",
      "global_step= 262  losses= 0.34129724  time=102.101306s\n",
      "global_step= 263  losses= 0.34173712  time=99.636287s\n",
      "global_step= 264  losses= 0.32909894  time=98.582305s\n",
      "global_step= 265  losses= 0.3364841  time=98.810250s\n",
      "global_step= 266  losses= 0.35648945  time=98.412254s\n",
      "global_step= 267  losses= 0.32326454  time=98.567249s\n",
      "global_step= 268  losses= 0.31432727  time=98.775210s\n",
      "global_step= 269  losses= 0.36518493  time=98.897264s\n",
      "global_step= 270  losses= 0.31640983  time=98.681286s\n",
      "global_step= 271  losses= 0.3372502  time=99.996226s\n",
      "global_step= 272  losses= 0.33954772  time=98.766272s\n",
      "global_step= 273  losses= 0.33352384  time=100.215281s\n",
      "global_step= 274  losses= 0.33105448  time=98.777331s\n",
      "global_step= 275  losses= 0.38777223  time=98.751304s\n",
      "global_step= 276  losses= 0.3239617  time=98.488282s\n",
      "global_step= 277  losses= 0.33180615  time=98.722270s\n",
      "global_step= 278  losses= 0.36881492  time=98.630241s\n",
      "global_step= 279  losses= 0.3548747  time=97.905206s\n",
      "global_step= 280  losses= 0.31659853  time=98.606307s\n",
      "model saved to ckp-000280\n",
      "global_step= 281  losses= 0.33313274  time=102.965241s\n",
      "global_step= 282  losses= 0.378816  time=101.012232s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6f86c3e9c199>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mbatch_squared_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_blured_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             global_step_val,losses,losses_merged,_= sess.run([global_step,loss,merged,train_op],\n\u001b[1;32m---> 33\u001b[1;33m                                                           feed_dict={x_image:batch_blured_img , y_image:batch_squared_img})\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0muse_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "train_steps = 100000\n",
    "img_set = Image_set()\n",
    "\n",
    "\n",
    "model_dir = '.\\\\run_model'\n",
    "log_dir ='.\\\\run_log'\n",
    "test_dir = '.\\\\test_img'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(log_dir,sess.graph)\n",
    "    sess.run(init_op)\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, os.path.join(model_dir, ckpt_name))\n",
    "        \n",
    "    test  = True    \n",
    "    for step in range(train_steps):\n",
    "    #for step in range(1):\n",
    "        if not test:\n",
    "            start_time = time.time()\n",
    "            batch_squared_img,batch_blured_img = img_set.next_batch(batch_size)\n",
    "            global_step_val,losses,losses_merged,_= sess.run([global_step,loss,merged,train_op],\n",
    "                                                          feed_dict={x_image:batch_blured_img , y_image:batch_squared_img})\n",
    "        \n",
    "            use_time = time.time()-start_time\n",
    "            print(\"global_step=\",global_step_val,\" losses=\",losses,\" time=%02fs\"%use_time)\n",
    "        \n",
    "            if global_step_val%20 ==0:\n",
    "                writer.add_summary(losses_merged,global_step_val)\n",
    "                saver.save(sess,os.path.join(model_dir,'ckp-%06d' %global_step_val))\n",
    "                print('model saved to ckp-%06d' %global_step_val)\n",
    "                test = True\n",
    "            \n",
    "        else:    #每20步测试一下图片生成情况\n",
    "            batch_squared_img,batch_blured_img = img_set.next_batch(1)\n",
    "            global_step_val,generated_imgs = sess.run([global_step,y_image_predict],\n",
    "                                                        feed_dict={x_image:batch_blured_img , y_image:batch_squared_img})\n",
    "            #不训练执行train_op的时候，global_step_val不会+1\n",
    "            img = generated_imgs[-1]\n",
    "            img = (img+1)*127.5\n",
    "            img = np.array(img,dtype = np.uint8)\n",
    "            out_put_path = os.path.join(test_dir,\"%06d.jpg\" %global_step_val)\n",
    "            cv2.imwrite(out_put_path,img)\n",
    "            #cv2.imshow('a',img)\n",
    "            #cv2.waitKey()\n",
    "            test = False\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
